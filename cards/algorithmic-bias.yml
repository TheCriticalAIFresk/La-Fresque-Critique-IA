card_number: 4
card_set: 2
url: https://github.com/TheCriticalAIFresk/La-Fresque-Critique-IA/cards/algorithmic-bias.yml
img: assets/imgs/algorithmic-bias.png
title_en: Algorithmic Bias
description_en: Algorithms can produce unfair or skewed outcomes that reflect biases in the training data or design choices. These biases can reproduce and even amplify existing forms of discrimination.
title_fr: Biais Algorithmiques
description_fr: Les algorithmes peuvent produire des résultats injustes ou faussés, reflétant des biais dans les données d'apprentissage ou des choix de conception. Ces biais peuvent reproduire, voire amplifier, des formes de discrimination existantes.
bibliography:
  - "Angwin, J., Larson, J., Mattu, S., & Kirchner, L. (2016). Machine Bias. There is software that is used across the county to predict future criminals. And it is biased against blacks. Retrieved from: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"
  - "Waardenburg, L., Sergeeva, A., & Huysman, M. (2018). Hotspots and blind spots: A case of predictive policing in practice. In Living with Monsters? Social Implications of Algorithmic Phenomena, Hybrid Agency, and the Performativity of Technology: IFIP WG 8.2 Working Conference on the Interaction of Information Systems and the Organization, IS&O 2018, San Francisco, CA, USA, December 11-12, 2018, Proceedings (pp. 96-109). Springer International Publishing."
  - "Amoore, L. (2006). Biometric borders: Governing mobilities in the war on terror. Political Geography, 25 (3), 336-351, ISSN 0962-6298. https://doi.org/10.1016/j.polgeo.2006.02.001"
